/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    nf-core/curioseeker Nextflow config file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Default config options for all compute environments
----------------------------------------------------------------------------------------
*/

// Global default params, used in configs
params {

    // Input options
    input                                = null
    fastq_chunk_size                     = 5000000
    bam_chunk_size                       = 5000000
    unique_cellular_barcodes_chunk_size  = 3000000
    gene_chunk_size                      = 1000
    bb_min                               = 10
    //barcode_chunk_size                   = 165000
    max_beads                            = 10000000
    top_bb_chunk_size                    = 1000000

    //extend_qc                            = false
    //extend_primary_qc                    = false
    //generate_combined_database           = false
    //run_seekerexplorer                   = false

    // Omics Options
    omics                      = false
    omics_results_dir          = null
    dnanexus                   = false

    // Curio Seeker Python Execution Options
    // Use Conda environment, Singularity container, or Docker container
    // curio_seeker_conda = '/apps/easybuild/4.5.4/software/curio-seeker/0.0.1/'
    curio_seeker_conda          = ''
    // 'file:////home/Users/.singularity/curio-seeker-singularity:2024.02.22.sif'
    curio_seeker_singularity    = 's3://curioseekerbioinformatics/CurioSeeker_v2.5.0/curio-seeker-singularity-2024.02.22.sif'
    curio_seeker_docker         = 'docker.io/curiobioinformatics/curio-seeker-pipeline:2024.02.22'

    // References
    genome                     = 'GRCm38'
    igenomes_base              = ''
    igenomes_ignore            = false

    // Markdown files
    rep_file                    = "${projectDir}/bin/htmlrender.Rmd"
    rep_file_ext                = "${projectDir}/bin/htmlrender_extended.Rmd"

    // MultiQC options
    //multiqc_config             = null
    //multiqc_title              = null
    //max_multiqc_email_size     = '25.MB'

    // Index Options
    // Build star index. If you've already downloaded the index you won't need to do this
    build_star_index            = false

    // --sjdbGTFfile specifies the path to the file with annotated transcripts in the standard GTF
    // format. STAR will extract splice junctions from this file and use them to greatly improve
    // accuracy of the mapping. While this is optional, and STAR can be run without annotations,
    // using annotations is highly recommended whenever they are available. Starting from 2.4.1a,
    // the annotations can also be included on the fly at the mapping step
    supply_sjdb_gtf_file       = true
    star_ignore_sjdbgtf        = false

    // Boilerplate options
    outdir                     = null
    tracedir                   = "${params.outdir}/pipeline_info"
    publish_dir_mode           = 'copy'
    email                      = null
    email_on_fail              = null
    plaintext_email            = false
    monochrome_logs            = false
    help                       = false
    validate_params            = true
    show_hidden_params         = false
    schema_ignore_params       = 'genomes'
    enable_conda               = false

    // Config options
    custom_config_version      = 'master'
    custom_config_base         = "https://raw.githubusercontent.com/nf-core/configs/${params.custom_config_version}"
    config_profile_description = null
    config_profile_contact     = null
    config_profile_url         = null
    config_profile_name        = null

    // Max resource options
    // Defaults only, expecting to be overwritten
    max_memory                 = '256.GB'
    max_cpus                   = 48
    max_time                   = '240.h'
    dataset_size               = "standard"
    // dataset_size = "million" for 3x3 datasets < 1 billion reads (datasets_million.config)
    // dataset_size = "billion" for 10x10 datasets >= 1 billion reads (datasets_billion.config)
    // dataset_size = "standard" use process labels (base.config, datasets_standard.config) with upgraded instance sizing
}

// Decide default (standard) process label config, million, or billion profile
includeConfig 'conf/datasets_all.config'

// Load base.config by default for all pipelines
// Defines error and error retry strategy
includeConfig 'conf/base.config'

// Load nf-core custom profiles from different Institutions
try {
    includeConfig "${params.custom_config_base}/nfcore_custom.config"
} catch (Exception e) {
    System.err.println("WARNING: Could not load nf-core/config profiles: ${params.custom_config_base}/nfcore_custom.config")
}

if (params.omics) {
    process.debug          = true
    workflow.profile       = 'docker'
    conda.enabled          = false
    docker.enabled         = true
    singularity.enabled    = false
    includeConfig 'conf/omics_containers.config'
    includeConfig 'conf/curioseeker_omics.config'
}

profiles {
    debug { process.beforeScript = 'echo $HOSTNAME' }
    conda {
        params.enable_conda    = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    docker {
        docker.enabled         = true
        docker.userEmulation   = true
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    dnanexus {
        docker.enabled         = true
        docker.userEmulation   = true
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        includeConfig 'conf/dnanexus.config'
    }
    singularity {
        singularity.enabled    = true
        singularity.autoMounts = true
        docker.enabled         = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    podman {
        podman.enabled         = true
        docker.enabled         = false
        singularity.enabled    = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    shifter {
        shifter.enabled        = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        charliecloud.enabled   = false
    }
    charliecloud {
        charliecloud.enabled   = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
    }
    test      { includeConfig 'conf/test.config'      }
    test_full { includeConfig 'conf/test_full.config' }
}

// Load igenomes.config if required
if (!params.igenomes_ignore) {
    includeConfig 'conf/igenomes.config'
} else {
    //params.genomes = [:]
    includeConfig 'conf/genomes.config'
}

// Export these variables to prevent local Python/R libraries from conflicting with those in the container
// The JULIA depot path has been adjusted to a fixed path `/usr/local/share/julia` that needs to be used for packages in the container.
// See https://apeltzer.github.io/post/03-julia-lang-nextflow/ for details on that. Once we have a common agreement on where to keep Julia packages, this is adjustable.

env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
    JULIA_DEPOT_PATH = "/usr/local/share/julia"
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.tracedir}/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.tracedir}/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.tracedir}/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.tracedir}/pipeline_dag_${trace_timestamp}.svg"
}

manifest {
    name            = 'nf-core/curioseeker'
    author          = 'Curio'
    homePage        = 'https://github.com/nf-core/curioseeker'
    description     = 'Curio Seeker Pipeline'
    mainScript      = 'main.nf'
    nextflowVersion = '!>=21.10.3'
    version         = '2.5'
}

// Load modules.config for DSL2 module specific options
includeConfig 'conf/modules.config'

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}

// this always fails if process is set to low
process {
  errorStrategy = 'retry'
  maxRetries = 2
}

